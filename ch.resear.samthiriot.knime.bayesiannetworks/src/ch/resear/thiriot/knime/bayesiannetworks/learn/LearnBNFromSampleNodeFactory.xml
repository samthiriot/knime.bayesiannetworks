<?xml version="1.0" encoding="UTF-8"?>
<knimeNode icon="../bn-icon.png" 
			type="Learner" 
			xmlns="http://knime.org/node/v2.8" 
			xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
			xsi:schemaLocation="http://knime.org/node/v2.10 http://knime.org/node/v2.10.xsd">

    <name>Learn BN From Sample</name>
    
    <shortDescription>
        For a given Bayesian network, learns the conditional probabilities from a given sample
    </shortDescription>
    
    <fullDescription>
        <intro>
        For a given Bayesian network, learns the conditional probabilities from a given sample.
        <br />
        In practice, it is often recommanded to add a constant of +1 to the measured counts. 
		This reduces the problem of zero cells, in which zero cells might happen because the sample
		was to small, not because it is structurally impossible to see the case in reality.
		This also smoothes the sampling effect in general. 
		Yet it also adds a bias in the measure.
        You might add such a constant using the smoothing constant parameter which 
        is defined by default at 0.
        </intro>
        
        <option name="Smoothing constant">constant to add to the count found in the actual sample (default to 0)</option>
    </fullDescription>
    
    <ports>
        <inPort index="0" name="Bayesian network">Bayesian network</inPort>
        <inPort index="1" name="Sample">Date table with the sample to learn</inPort>
        
        <outPort index="0" name="Bayesian network">Learnt Bayesian network</outPort>

    </ports>    
  
</knimeNode>